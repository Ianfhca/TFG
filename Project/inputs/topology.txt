-- PARAMETERS --

# Time stages (m, s, ms, us, ns)
time 1 s # Delete this value
#learning_rate
#dt 1000 us #Integer value gratter than 0
dt 10000 us
#dt 500 us
>

-- HYPERPARAMETERS --

# Type 0 (Default)
v_reset -65.0
v_rest -65.0
v -65.0
v_th -64.0
#v_th -50.0
lambda_v 20.0
t_refr 2
lambda_x 20.0
alpha 0.1
#weights 0.5
#learning_rate 0.0001
#a 0
#convergence_th 0.05
>

# Type 1
v_reset -60.0
v_rest -60.0
v -60.0
v_th -45.0
lambda_v 20.0
t_refr 1
lambda_x 20.0
alpha 0.1
>

-- TOPOLOGY --

# Layer 0 (Input Layer)
layer Input
neurons 128 128 2 # (Height x Width x Channels)
type 0
connections none
multisynapses 1
delay 1 1 # (Same unit as dt)
>

# Layer 1 (Feature Extraction)
layer SS-Conv
neurons 0
type 0
connections local
kernel_size 5 # (window size rxr)
kernels_amount 2 # (output maps k)
multisynapses 1
delay 5000 15000
>

# Layer 5 (Global Motion Perception)
layer Dense
neurons 11 1 1
type 0
connections dense
multisynapses 1
#delay 1500 1500
delay 5000 15000
>

# Layer 6 (Class prediction)
layer Output
neurons 11 1 1
type 0
connections sparse
sparse_connection 0 0
sparse_connection 1 1
sparse_connection 2 2
sparse_connection 3 3
sparse_connection 4 4
sparse_connection 5 5
sparse_connection 6 6
sparse_connection 7 7
sparse_connection 8 8
sparse_connection 9 9
sparse_connection 10 10
multisynapses 1
delay 1 1
>
#connections sparse
#sparse_connection 0 0
#sparse_connection 1 1
#sparse_connection 2 1
#sparse_connection 3 0

#----------------------------------------------------------------------------------------------------------------
# Falta realizar correctamente las sparse connections

# Sparse connections de capa 0 a capa 1

#connections sparse
#sparse_connection 0 0
#sparse_connection 1 1
#sparse_connection 2 1
#sparse_connection 3 0

# Tener en cuenta los delays acumulados para la finalización de la simulación

#lamdaX = -1/tau_m

# Comprobar que la forcing function no sea += en vez de = ·
# Arreglar delays ·
# Funcionamiento multisinapsis ·
# Corregir updateNeuron. Mirar si forcing function se tiene que hacer para multisyinapsis tambn. for(i; i < multisyinapsis; i++) ·
# Separar ficheros datos y estructura ·
# Enlazar dataset ·
# STDP (Backpropagation) ·
# TODO ------------------------------------------------------------------------------------- Modificar t del membrane potential

# Cambiar nombres tau etc. para los delays (Jose)

# a and learning_rate as parameters

# Documentar cada método
# Gráficos


# Falta hacer bucle para recorrer todos los gestos de todos los ficheros de train. ·
# Falta ajustar el dt para que coincida con el dt pasado por parametro. ·
# Falta formula MSE del STDP.
# Falta guardar pesos en fichero binario e implementar test.
# Falta salida de la red ????
# Falta graficos (mapa de calor, MSE...)

# Preguntas JOSE:
# El forcing function hay que sumarlo?
# Que es la salida de la red? - Simplemente guardar las spikes de salida
# Limitaciones pesos y trazas preX? (Sinapsis.cpp entre 0 y 1) Apendice B paper - No
# El ganador es el que actualiza el STDP solamente? - Si
# Las locally connected neurons comparten pesos? Hay que tener una W en neuron en la que se haga el dot product de todas las synapsis? - No


# Los setWeight() hay que sumar o no? +=
# la neurona 13078 deja de aprender
# la traza presinaptica y los pesos se están normalizando mal puede
